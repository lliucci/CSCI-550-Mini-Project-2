---
title: "CSCI 550 - Project 2"
author: "Eliot Liucci, Eric Folsom, Nick Clausen, Christal O'Connell"
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2:
    fig_height: 4
    fig_width: 8
    extra_dependencies: ['amsmath', 'float']
    number_sections: true
    toc: false
fontsize: 12pt
spacing: double
indent: true
header-includes:
  \usepackage{float}
  \floatplacement{figure}{H}
bibliography: mini_project_2.bib
---

```{r, setup, include=FALSE}
require(mosaic)   # Load additional packages here 
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small",   # slightly smaller font for code
  warning = F,    # display warnings
  message = F,    # display messages
  echo = T,       # display code
  eval = F,       # evaluate code
  fig.pos = "H")  # holdings figures in position

# Packages
library(tidyverse)
library(ggmap)
library(sf)
library(caret)
theme_set(theme_bw())

# Data Reading
data = read_csv("data_cleaned.csv")

# Converting Columns into factors with levels
data <- data %>%
  mutate(Property_Class = factor(Property_Class),
         Neighborhood_Code = factor(Neighborhood_Code),
         Town_Code = factor(Town_Code),
         Apartments = factor(Apartments),
         Wall_Material = factor(Wall_Material),
         Roof_Material = factor(Roof_Material),
         Basement = factor(Basement),
         Basement_Finish = factor(Basement_Finish),
         Central_Heating = factor(Central_Heating),
         Other_Heating = factor(Other_Heating),
         Central_Air = factor(Central_Air),
         Attic_Type = factor(Attic_Type),
         Attic_Finish = factor(Attic_Finish),
         Design_Plan = factor(Design_Plan),
         Cathedral_Ceiling = factor(Cathedral_Ceiling),
         Construction_Quality = factor(Construction_Quality),
         Site_Desirability = factor(Site_Desirability),
         Garage_1_Size = factor(Garage_1_Size),
         Garage_1_Material = factor(Garage_1_Material),
         Garage_1_Attachment = factor(Garage_1_Attachment),
         Garage_1_Area = factor(Garage_1_Area),
         Garage_2_Size = factor(Garage_2_Size),
         Garage_2_Material = factor(Garage_2_Material),
         Garage_2_Attachment = factor(Garage_2_Attachment),
         Garage_2_Area = factor(Garage_2_Area),
         Porch = factor(Porch),
         Other_Improvements = factor(Other_Improvements),
         Repair_Condition = factor(Repair_Condition),
         Multi_Code = factor(Multi_Code),
         Multi_Property_Indicator = factor(Multi_Property_Indicator),
         OHare_Noise = factor(OHare_Noise),
         Floodplain = factor(Floodplain),
         Road_Proximity = factor(Road_Proximity),
         Sale_Quarter_of_Year = factor(Sale_Quarter_of_Year),
         Sale_Half_of_Year = factor(Sale_Half_of_Year),
         Most_Recent_Sale = factor(Most_Recent_Sale),
         Pure_Market_Filter = factor(Pure_Market_Filter),
         Garage_Indicator = factor(Garage_Indicator),
         Fireplaces = factor(Fireplaces),
         Number_of_Commercial_Units = factor(Number_of_Commercial_Units),
         Area = factor(Area),
         Sub_Area = factor(Sub_Area),
         Block = factor(Block),
         Parcel = factor(Parcel),
         Multicode = factor(Multicode)
  )


# Setting up for spatial plots
register_google(key = "AIzaSyCnq3okTIRjxfQ0wHWGyu08HGCrFtIQo4M", write = TRUE)
Map <- get_googlemap(center = c(long = -87.8,lat = 41.8), maptype = "satellite", zoom = 9)
cook_map2 <- read_sf('Congressional_District.geojson')
cook_map_overlay = st_transform(cook_map2)
cook_map <- map_data('county', 'illinois') |> filter(subregion == 'cook')

```

\vfill

# Executive Summary

This project aims to determine the most optimal information to collect on real estate listings in the Chicago area. This was done by scraping data from 2013 to 2019 and collecting variables relating to the area of a listing and physical properties of the listing. When searching for the variables that best explain sale price in the Chicago area, exploratory data analysis found that the size of the listing, number of rooms present, estimated value, and additional quality of life features like a garage or fireplaces are the best predictors. To further determine best predictors, various models were fit and compared. We formally recommend using the estimate of the value of land a listing was built on and the estimate of the building itself as the main factors for determining how much a listing will sell for.

\newpage  

# Data Preprocessing and Exploration

## Data Cleaning

The data received had a few issues that needed to be dealt with. First of all, the `Description` variable contained pieces of key information that were extracted (number of bathrooms, number of bedrooms, total number of rooms, and sell date). Additionally, Area, Sub-Area, Block, Parcel, and Multicode were parsed from the `PIN` variable.

```{r}
# Extracting important information from descriptions
sell_date = as.numeric(0)
rooms = as.numeric(0)
bedrooms = as.numeric(0)
baths = as.numeric(0)

# Takes a minute to run, not too bad though
for(i in 1:nrow(data)){
    sell_date[i] = str_split(
        str_split(data$Description[i], "sold on ")[[1]][2],
         ", is a")[[1]][1]
    rooms[i] = str_extract_all(
        str_split(data$Description[i], "total of ")[[1]][2],
         "\\d")[[1]][1]
    bedrooms[i] = str_extract_all(
        str_split(data$Description[i], "total of ")[[1]][2],
         "\\d")[[1]][2]
    baths[i] = str_split(
        str_split(data$Description[i], "bedrooms, and ")[[1]][2],
         " of which are bathrooms")[[1]][1]
    Area[i] = substring(data$PIN[i], first = 1, last = 2)
    Sub_Area[i] = substring(data$PIN[i], first = 3, last = 4)
    Block[i] = substring(data$PIN[i], first = 5, last = 6)
    Parcel[i] = substring(data$PIN[i], 7, 8)
    Multicode[i] = substring(data$PIN[i], 9, 12)
}
```

Once these variables were extracted, the `Description` variable was dropped from the data set. We noticed some houses with strange recording like "42 bathrooms and 7 rooms", so we dropped any listings where the number of bedrooms and number of bathrooms was greater than the total recorded number of rooms.

```{r}
# Adding features of descriptions, removing descriptions
data = data %>%
    mutate(
      Sell_Date = mdy(sell_date),
      Rooms = as.numeric(rooms),
      Bedrooms = as.numeric(bedrooms),
      Baths = as.numeric(baths)
    ) %>%
    select(-Description)

# Removing rows where num bathrooms/bedrooms exceeds number of rooms
data = data %>%
    filter(Bedrooms < Rooms | Baths < Rooms)
```

Next, we dropped any listings with a missing value in at least one of the variables.

```{r}
# Removing rows with at least 1 missing value
data = data %>%
    drop_na()
```

We also wanted to deal with outliers, so a function was written that would identify a listing as an outlier if it was greater than 3 standard errors away from the mean value and used this to remove outliers for variables where the maximum value was significantly higher than the 3rd quartile.

```{r}
# Filtering extreme observations
is_outlier = function(x){
    result = abs(x - mean(x)) > 3*sd(x)
    return(result)
}

# Removing outliers for variables where max() is greater than q3()
data = data %>%
    filter(!is_outlier(`Sale Price`),
           !is_outlier(`Land Square Feet`),
           !is_outlier(Baths),
           !is_outlier(`Lot Size`),
           !is_outlier(`Town and Neighborhood`),
           !is_outlier(`Age Decade`),
           !is_outlier(`Age`),
           !is_outlier(`Estimate (Land)`),
           !is_outlier(`Estimate (Building)`),
           !is_outlier(`Building Square Feet`),
           !is_outlier(`Other Improvements`))
```

Finally, we removed all spaces from variable names and replaced them with underscores.

```{r}
# Removing Spaces
data = data %>%
  rename(Property_Class = `Property Class`,
        Neighborhood_Code = `Neighborhood Code`,
        Land_Square_Feet = `Land Square Feet`,
        ...
        Age_Decade = `Age Decade`,
        Neighborhood_Code_Mapping = `Neigborhood Code (mapping)`,
        Town_and_Neighborhood = `Town and Neighborhood`,
        )
```

This cleaned data set was written as `data_cleaned.csv` so it could easily be reloaded for the remainder of the analysis.

```{r}
# Save cleaned data
write_csv(data, "data_cleaned.csv")
```

## Exploration of Data

Within the data, latitude and longitude coordinates were provided for each listing. A map of the sale price of listings is overlaid on a satellite map of the region (Figure \@ref(fig:SalePriceSatMap)). Here, it can be seen that a lot of the higher price listings are on the water, with sale price generally decreasing the more in-land the listing is.

```{r SalePriceSatMap, fig.cap = "A spatial map of the sale prices over the region.", fig.height = 8, eval = T}
# Spatial Map of Sale Price
ggmap(Map, darken = c(0.1, "white")) +
    geom_polygon(data = cook_map, aes(x = long, y = lat), 
        fill = NA, color = "orange") +
    geom_point(data = data, 
                aes(x = Longitude, 
                    y = Latitude, 
                    color = Sale_Price), 
                size = 0.02, 
                alpha = 0.75) +
    scale_color_gradient(low = "#6fe7f7", high = "#890000") +
    labs(x = "Longitude", y = "Latitude", color = "Sale Price ($)")
```

Multiple boxplots were created for all of the variables pertaining to a garage against the response (Figure \@ref(fig:GarageVarBoxplots)). As the first garage increases in size, so too does the sale price. Having a garage attached to the building (`Garage_#_Attachement` = 1) is also associated with a higher sale price for both garage 1 and garage 2. Higher quality materials (larger values of `Garage_#_Material`) is associated with higher sale prices too.

```{r GarageVarBoxplots, fig.cap = "A series of boxplots for all garage variables against sale price.", eval = T}
# Plotting Against Garage Variables
data %>%
    select(Sale_Price, 
           Garage_1_Area, 
           Garage_1_Size, 
           Garage_1_Attachment, 
           Garage_1_Material, 
           Garage_2_Area, 
           Garage_2_Size, 
           Garage_2_Attachment, 
           Garage_2_Material) %>%
    pivot_longer(cols = 2:9, names_to = "Variable", values_to = "Value") %>%
    ggplot(aes(x = factor(Value), y = Sale_Price, group = Value)) +
    geom_boxplot() +
    facet_wrap(~Variable, scales = "free_x", nrow = 2) +
    labs(x = " ")
```

When comparing sale price to variables related to the physical property, it can be noted that for the `Apartments` variable, there is large varibility in the "0" group, which may be due to non-apartment buildings being more expensive (Figure \@ref(fig:PropertyVarBoxplots)). Sale price is generally the same across attic types, porch groups, and design plans. Sale price appears to increase as the number of fireplaces increases. Additionally, sale price is higher for listings with cathedral ceilings. The `Proprty_Class` variable apperas to have equal variability in sale price for all classes except "209".

```{r PropertyVarBoxplots, fig.cap = "A series of boxplots for variables related to the property itself.", eval = T}
data %>%
    select(`Sale_Price`, 
            `Property_Class`,
            `Apartments`,
            `Basement`,
            `Attic_Type`,
            `Design_Plan`,
            `Cathedral_Ceiling`,
            Fireplaces,
            Porch) %>%
    pivot_longer(cols = 2:9, names_to = "Variable", values_to = "Value") %>%
    ggplot(aes(x = factor(Value), y = Sale_Price, group = Value)) +
    geom_boxplot() +
    facet_wrap(~Variable, scales = "free_x", nrow = 2) +
    labs(x = " ")
```

Additional boxplots were created for the number of rooms in each listing (Figure \@ref(fig:RoomVarBoxplots)). For all room variables, there is generally an increase in sale price as the number of rooms increases. However, the sale price for listings with 1 room is higher, on average, than all other room groups. The same goes for listings with 0 bedrooms.

```{r RoomVarBoxplots, fig.cap = "A series of boxplots for the variables relating to number of rooms present.", eval = T}
# Plotting Against Room Variables
data %>%
    select(`Sale_Price`, 
            `Bedrooms`,
            `Baths`,
            `Rooms`) %>%
    pivot_longer(cols = 2:4, names_to = "Variable", values_to = "Value") %>%
    ggplot(aes(x = factor(Value), y = Sale_Price, group = Value)) +
    geom_boxplot() +
    facet_wrap(~Variable, scales = "free_x") +
    labs(x = " ")
```

The final visualization of interest is a scatterplot of sale price against both building square footage and land square footage (Figure \@ref(fig:BuildingLandSize)). Here, it can be seen that for listings with high building square footage, we see higher sale price. The relationship is the same for land square footage, although the highest sale prices occur at high building square footage and average land square footage.

```{r BuildingLandSize, fig.cap = "A scatterplot of the relationship between sale price and building/land square footage.", eval = T}
data %>%
    ggplot(aes(x = `Building_Square_Feet`, 
                y = `Land_Square_Feet`, 
                color = `Sale_Price`)) +
    geom_point(size = 2) +
    labs(x = "Building Square Footage",
        y = "Land Square Footage",
        color = "Sale Price ($)")
```

## Hypothesis Development

From the exploration performed above, we hypothesize that building square footage, land square footage, the number of rooms, and location are likely going to have the highest impact on sale price.

# Model Development and Performance Evaluation

Before starting the modelling process, variables were factored (if categorical) or scaled to have mean of 0 and variance 1 (if quantitative). This ensured that models had the best chance of converging. Additionally, some variables were removed due to having only 1 value or being of no importance.

```{r ModelData, eval = T}
# Scaling numeric variable
Model_Data = data %>%
    select(-c(Modeling_Group,
            Age,
            Use,
            Sale_Half_of_Year,
            `...1`,
            PIN,
            Census_Tract,
            Deed_No,
            Town_and_Neighborhood,
            Neighborhood_Code_Mapping)) %>%
    mutate(Land_Square_Feet = scale(Land_Square_Feet),
            Building_Square_Feet = scale(Building_Square_Feet),
            Estimate_Land = scale(Estimate_Land),
            Estimate_Building = scale(Estimate_Building),
            Lot_Size = scale(Lot_Size)) %>%
    filter(Sale_Price > 499)
```

At this point, the data were split into training and testing sets by randomly sampling 80% of the rows for the training set and leaving the remaining rows for the testing set.

```{r TrainTestSplit, eval = T}
# Sampling rows at random
ids_train = sample(1:nrow(Model_Data), 
                size = round(0.8*nrow(Model_Data)), 
                replace = FALSE)

# Splitting data
train = Model_Data[ids_train,]
test = Model_Data[-ids_train,]
```

To find the best Simple Linear Regression model, all single predictor models were searched and compared on AIC. The top-performing model involved the predictor `Estimate_Building` to predict sale price. A summary of the model fit using K-fold cross-validation is shown below. Note that the $R^2$ indicates fairly poor model fit, but this is to be expected as it is only a single predictor.

```{r SLR, eval = T}
# Define cross-validation method with 5 folds
train_control <- trainControl(method = "cv", 
                              number = 5)
 
 
# Build model using linear model
slr <- train(Sale_Price~Estimate_Building, data = train, 
               trControl = train_control, 
               method = "lm")

# Summary of model
print(slr)

slr_preds = predict(slr, test)
slr_mse = Metrics::mse(slr_preds, test$Sale_Price)
print(paste("MSE from Test Set: ", slr_mse))
```

To find the best Multiple Linear Regression model, we used all available predictors with no interactions. A summary of the cross-validation process is provided. Then, we predicted to the test data and calculated the mean squared error.

```{r MLR, eval = T}
# Train mly model using k-fold cross validation
mlr <- train(Sale_Price~., data = train, 
               trControl = train_control, 
               method = "lm")

# Print model specifications
print(mlr)

# Predict to test data
mlr_preds = predict(mlr, test)
mlr_mse = Metrics::mse(mlr_preds, test$Sale_Price)
print(paste("MSE from Test Set: ", mlr_mse))
```

Starting with the MLR model, subset selection was performed via backwards selection. Each iteration, the term that had the lowest impact on AIC was removed until no other terms needed to be removed. Once the ideal model formula was determined, this model was re-fit using 5-fold cross-validation.

```{r}
# Refit MLR model
mlr = lm(Sale_Price ~ ., data = train)

# Determine best model
best_subset <- MASS::stepAIC(mlr, direction = "backward", scope = ~ 1)

# Refit best model
best_subset <- train(Sale_Price ~ 1,
                    data = train,
                    trControl = train_control,
                    method = 'lm')

# Print model specifications
print(best_subset)

# Predict to test data
bs_preds = predict(best_subset, test)
bs_mse = Metrics::mse(bs_preds, test$Sale_Price)
print(paste("MSE from Test Set: ", bs_mse))
```

We fit Ridge and Lasso regression models using am mixutre of the `caret` and `glmnet` packages. `glmnet` was used to find the sequence of $\lambda$ values to choose from, while `caret` was used to ensure consistency with how we fit our other models. Ridge and Lasso regression can be easily fit using the `glmnet` package alone.

```{r, RidgeLasso, eval =T}
library(glmnet)
data.train.mat <- model.matrix(Sale_Price ~. , data = train)[,-1]
data.test.mat <- model.matrix(Sale_Price ~., data = test)[,-1]


# Fitting ridge regression model 
tune.grid.ridge = expand.grid(alpha = 0,
                           lambda = glmnet(data.train.mat,
                                    train$Sale_Price, 
                                    alpha = 0)$lambda)
fit.ridge <- train(Sale_Price ~ ., data = train,
  method = 'glmnet',
  trControl = train_control,
  tuneGrid = tune.grid.ridge)

# Tuning Parameters 
print(fit.ridge)

# fitting the model on the test data
ridge_pred <- predict(fit.ridge, test)
ridge_mse = Metrics::mse(ridge_pred, test$Sale_Price)
print(paste("MSE from Test Set: ", ridge_mse))
# model coefficients
coef(fit.ridge$finalModel, s = fit.ridge$bestTune$lambda)


# Fitting Lasso regression model
tune.grid.lasso = expand.grid(alpha = 1,
                           lambda = glmnet(data.train.mat,
                                    train$Sale_Price,
                                    alpha = 1)$lambda)
fit.lasso <- train(Sale_Price ~., data = train,
                    method = 'glmnet',
                    trControl = train_control,
                    tuneGrid = tune.grid.lasso)

# Tuning Parameters
print(fit.lasso)
# Fitting the model on our test data
lasso_pred <- predict(fit.lasso, test)
lasso_mse = Metrics::mse(lasso_pred, test$Sale_Price)
print(paste("MSE from Test Set: ", lasso_mse))
# model coefficients
coef(fit.lasso$finalModel, s = fit.lasso$bestTune$lambda)
```

For the model using principle components, we first selected all numeric variables except for the response and calculated the principle components. The cumulative variance is shown below, indicating that only the first two principle components are needed.

```{r PCs, eval = T}
# Calculating principle components using numeric data
numeric_data = Model_Data %>% select_if(is.numeric) %>% select(-Sale_Price)
PCs = prcomp(numeric_data)

# Determining how many PCs to use
PCs$sdev^2/sum(PCs$sdev^2)
```

Then, a data frame is created using the first two principle components' variable values. The observed response values were then binded to this data frame and the train-test splits were made again using the original training IDs. The model was trained on the training data using the 5-fold cross-validation and predictions were made on the test set. 

```{r PCsData, eval = T}
# Obtain first principle component as data
PC_data = data.frame(PCs$x[,1:2])

# Convert into data frame, adding response
PC_data = bind_cols(PC_data, data.frame(Sale_Price = Model_Data$Sale_Price))

# Split into test and train
PC_train = PC_data[ids_train,]
PC_test = PC_data[-ids_train,]

# train model with k-fold cv
pc_slr <- train(Sale_Price~., data = PC_train, 
               trControl = train_control, 
               method = "lm")

# display model
print(pc_slr)

# predict to test data
pc_slr_preds = predict(pc_slr, PC_test)
pc_mse = Metrics::mse(pc_slr_preds, PC_test$Sale_Price)
print(paste("MSE from Test Set: ", pce_mse))

# Loadings from first PC
PCs$rotation[,1]
```

A similar process was performed for the non-linear model as for the principle component model. We start by calculating the orthogonal $4^{th}$ degree polynomial variables from the `Estimate_Building` variable, renaming each term as `Poly_#`. This data set was binded with the original data as to have all polynomial variables and the response in a single data frame. Then, train and test splits were made. The model was trained on the training set and predicted to the testing set, resulting in the MSE provided.

```{r PolyModel, eval = T}
# Adding polynomial terms for later use
poly_predictors = data.frame(poly(Model_Data$Estimate_Building, 4))

Polynomial_Data = poly_predictors %>%
    rename(Poly_1 = X1,
           Poly_2 = X2,
           Poly_3 = X3,
           Poly_4 = X4) %>%
    bind_cols(Model_Data)

# Split polynomial data
poly_train = Polynomial_Data[ids_train,]
poly_test = Polynomial_Data[-ids_train,]

# Training 5th degree polynomial
poly_slr = train(Sale_Price ~ Poly_1 + Poly_2 + Poly_3 + Poly_4, 
                data = poly_train,
                trControl = train_control,
                method = 'lm')


# Summary of model
print(poly_slr)

# Predicting and Calculating MSE
poly_slr_preds = predict(poly_slr, poly_test, type = 'raw')
poly_mse = Metrics::mse(poly_slr_preds, poly_test$Sale_Price)
print(paste("MSE from Test Set: ", poly_mse))
```

Comparing the models on mean squared error when predicting to the test set, we can see which model performed the best when predicting to the test data (Table \@ref(tab:MSETable)). From this table, the top performing model on test data was _____.

```{r MSETable, eval = T}
tibble(Model = c("SLR", "MLR", "Backward Selection", 
                "Ridge", "Lasso", "PCA", "Polynomial"),
    MSE = c(slr_mse, mlr_mse, bs_mse, ridge_mse, lasso_mse, pc_mse)) %>%
    arrange(desc(MSE)) %>%
    knitr::kable(caption = "A table of MSE for the models compared when predicting to the test data.")
```